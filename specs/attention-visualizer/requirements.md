# 需求文档

## 介绍

本项目旨在为开源大语言模型（特别是Qwen系列）提供注意力可视化工具，专门用于提示词工程优化。通过直接从Hugging Face transformers模型中提取注意力权重并可视化，帮助工程师和研究者理解模型如何处理提示词，从而优化提示词设计。

### 背景
- 现有工具（如BertViz）对新模型支持有限，不支持Qwen等开源LLM
- 提示词优化目前只能依靠输出质量判断，缺乏可视化的量化分析手段
- 需要简单易用的工具快速分析模型对提示词不同部分的关注程度

## 需求

### 需求1：注意力权重提取
**用户故事：** 作为提示词工程师，我希望能从任意开源LLM中提取注意力权重，以便分析模型对输入文本的关注模式。

#### 验收标准
1. WHEN 用户调用可视化函数并传入模型、分词器和文本 THEN 系统 SHALL 成功从模型中提取注意力权重张量
2. IF 模型支持output_attentions参数 THEN 系统 SHALL 自动启用注意力输出并获取权重数据
3. WHEN 模型处理完成 THEN 系统 SHALL 返回形状为(batch, heads, seq_len, seq_len)的注意力张量

### 需求2：注意力热力图可视化
**用户故事：** 作为研究者，我希望将注意力权重以热力图形式展示，以便直观理解模型对提示词各部分的关注度。

#### 验收标准
1. WHEN 系统获得注意力张量 THEN 系统 SHALL 将最后一层的注意力权重平均化处理
2. WHEN 生成热力图 THEN 系统 SHALL 在x轴和y轴显示对应的token标签
3. IF 提示词长度超过显示限制 THEN 系统 SHALL 自动调整可视化布局以保持可读性
4. WHEN 热力图生成完成 THEN 系统 SHALL 显示颜色深度对应注意力权重强度的图表

### 需求3：简化的接口设计
**用户故事：** 作为工程师，我希望用一个函数调用就能完成从模型到可视化的全流程，以便快速进行提示词优化实验。

#### 验收标准
1. WHEN 用户调用主函数 THEN 系统 SHALL 只需要模型、分词器和文本三个必需参数
2. IF 用户未指定其他参数 THEN 系统 SHALL 使用合理的默认配置（最后一层、平均所有注意力头）
3. WHEN 函数执行 THEN 系统 SHALL 在10秒内完成可视化并显示结果
4. IF 出现错误 THEN 系统 SHALL 提供清晰的错误信息和解决建议

### 需求4：多模型兼容性
**用户故事：** 作为研究者，我希望工具支持不同的开源LLM，以便在不同模型间比较注意力模式。

#### 验收标准
1. WHEN 用户使用Qwen系列模型 THEN 系统 SHALL 正确提取和可视化注意力权重
2. IF 模型架构与标准Transformer兼容 THEN 系统 SHALL 自动适配并正常工作
3. WHEN 模型不支持注意力输出 THEN 系统 SHALL 提供明确的错误提示和替代建议

### 需求5：提示词优化支持
**用户故事：** 作为提示词工程师，我希望能快速识别提示词中模型最关注的部分，以便优化提示词结构。

#### 验收标准
1. WHEN 可视化完成 THEN 系统 SHALL 高亮显示注意力权重最高的token区域
2. IF 用户需要比较不同提示词 THEN 系统 SHALL 支持批量可视化和对比功能
3. WHEN 分析长文本提示词 THEN 系统 SHALL 提供注意力权重的统计摘要信息

## 核心功能优先级
1. **P0 - 核心功能**：基础注意力提取和HTML文本高亮可视化
2. **P1 - 重要功能**：简化接口和多模型支持  
3. **P2 - 未来功能**：
   - 批量对比、统计摘要
   - 完整Web应用版本（在线编辑提示词+实时可视化）
   - 交互式可视化增强功能

## 技术约束
- 使用Python 3.12+
- 基于transformers库和PyTorch
- 支持Windows 11环境
- 使用matplotlib进行可视化
- 遵循项目的简洁设计原则